# リスクを考慮したLLMの選定方法

AI駆動開発を安全に進めるには、**リスクと運用のバランスを考慮したLLM選択**が重要です。

## 情報漏洩リスク

AIツールを使う際、送信した機密情報が**学習データとして使われ、最悪の場合インターネット上に公開される**リスクがあります。

**このページでは、情報漏洩リスクを軽減するLLM選択方法を解説します。**

---

## LLMの提供方法は大きく3つ

LLMは大きく3つの方法で提供されています
それぞれの特徴を見ていきましょう

### 提供方法1. クラウド

**代表例**：
- OpenAI（ChatGPT）
- Anthropic（Claude）
- Google（Gemini）

**メリット**：
- すぐに使える
- 最新のモデルが利用可能
- 低コスト
- 運用負荷ゼロ

**デメリット**：
- データが外部サーバーに送信される
- 情報漏洩リスクが高い

**適している現場**：
- スタートアップ
- 個人開発者
- 機密情報を扱わないプロジェクト

**コスト例**：
- 無料〜月額$20（個人利用）
- $20〜$100/月（小規模チーム）

### 提供方法2. プライベートクラウド（VPC）

**プライベートクラウドとは**：AWS、Azure、GCPなどが**サービスとして提供するLLMを、自社のVPC内で利用**する方法です。

#### 仕組みの詳細

**AWS Bedrockを例に説明します：**

1. **Bedrockとは**：AWSが提供する「LLMのマーケットプレイス」のようなサービスです
2. **利用できるLLM**：Claude（Anthropic製）、Titan（AWS製）、Llama（Meta製）など、複数のLLMから選べます
3. **なぜAWSでClaudeが使えるのか**：AnthropicがAWSと提携し、AWS経由でClaudeを提供しているからです
4. **データはどこに送信される？**：
   - ✅ **自社のVPC内に留まります**
   - ✅ VPCエンドポイント経由で、外部インターネットを経由せずにLLMにアクセス
   - ✅ データは学習に使用されない契約
   - ❌ claude.aiなどの一般向けサービスには送信されません

**代表例**：
- AWS Bedrock（Claude、Titan等）
- Azure OpenAI Service（GPT-4等）
- Google Cloud Vertex AI（Gemini等）

**メリット**：
- データが自社のVPC内に留まる
- セキュリティコントロールが可能
- クラウドの利便性を維持
- スケーラブル

**デメリット**：
- 通常のクラウドLLMより高コスト
- 初期設定が必要
- 最新モデルが遅れて提供される場合がある

**コスト例**：
- Claude 3.5 Sonnet: $3/1Mトークン（入力）、$15/1Mトークン（出力）
- 月間100万トークン使用で約$20〜50

### 提供方法3. オンプレミス

**オンプレミスとは**：自社のサーバーやデータセンターに、LLMを直接インストールして運用する方法です。オープンソースのLLMモデルをダウンロードし、自社で管理・運用します。

**代表例**：
- Llama 3（Meta）
- Mistral
- Qwen
- 日本製LLM（Swallow、PLaMoなど）

**メリット**：
- データが完全に社内に留まる
- 最高レベルのセキュリティ
- インターネット接続不要

**デメリット**：
- 高性能GPUが必要（高コスト）
- 運用負荷が非常に高い
- 性能がクラウド版より劣る場合がある（サーバー性能が低いとAIの性能も下がる）

**適している現場**：
- 機密性が極めて高いプロジェクト
- 金融機関
- 政府機関

**必要なインフラ**：
```
GPU：NVIDIA A100 80GB × 4台以上
　　（Claude 3相当のモデルを動かす場合）

メモリ：256GB以上
ストレージ：2TB以上（SSD）

コスト：初期投資 ¥10,000,000〜
　　　　運用コスト ¥500,000/月〜
```

### デプロイ形態の比較表

| 形態         | セキュリティ  | コスト     | 性能     | 運用負荷  | 適した現場   |
| ---------- | ------- | ------- | ------ | ----- | ------- |
| クラウド       | △ 低い    | ◎ 低い    | ◎ 高い   | ◎ 低い  | スタートアップ |
| プライベートクラウド | ○ 中程度   | ○ 中程度   | ○ 高い   | ○ 中程度 | 中規模企業   |
| オンプレミス     | ◎ 非常に高い | × 非常に高い | △ 制約あり | × 高い  | 金融・政府   |

---

## プロバイダー別のセキュリティ評価

### OpenAI（ChatGPT、GPT-4）

| 項目 | 評価 | 詳細 |
|-----|------|------|
| データ保存 | △ | デフォルトで30日間保存、学習に使用される |
| Enterprise版 | ◎ | 学習に使用されない、SOC 2準拠 |
| 所在地 | ○ | アメリカ（GDPR対応あり） |
| 透明性 | ○ | ポリシーは公開されている |

**推奨設定**：
- 企業利用は ChatGPT Enterprise または API（オプトアウト設定）
- 個人利用でも機密情報は入力しない

### Anthropic（Claude）

| 項目 | 評価 | 詳細 |
|-----|------|------|
| データ保存 | ◎ | デフォルトで学習に使用されない |
| セキュリティ | ◎ | SOC 2 Type 2、HIPAA準拠 |
| 所在地 | ○ | アメリカ |
| 透明性 | ◎ | 非常に透明性が高い |

**推奨**：
- 企業利用に最も適している
- デフォルトでセキュアな設定

### Google（Gemini）

| 項目 | 評価 | 詳細 |
|-----|------|------|
| データ保存 | △ | 無料版は学習に使用される可能性 |
| ビジネス版 | ◎ | 学習に使用されない |
| 所在地 | ○ | アメリカ（複数リージョン対応） |
| 透明性 | ○ | ポリシーは公開されている |

**推奨設定**：
- Gemini for Business または Vertex AI を使用

---

## ⚠️ 中華プロバイダーの危険性

### DeepSeek（中国製LLM）の例

| 項目 | 評価 | 詳細 |
|-----|------|------|
| データ保存 | × | 不明確 |
| セキュリティ | × | 認証なし |
| 所在地 | × | 中国（データ保護法が異なる） |
| 透明性 | × | ポリシーが不明瞭 |

### なぜ危険なのか？

#### 1. データがどこに保存されるか不明

プライバシーポリシーが不明瞭で、送信したコードや機密情報がどこに保存され、誰がアクセスできるかわかりません。

#### 2. 中国のサイバーセキュリティ法

中国では**国家情報法**により、政府が企業に対してデータ提供を要求できます。つまり：

```
あなたの会社のコード
　↓ DeepSeekに送信
　↓ 中国のサーバーに保存
　↓ 中国政府が要求
　↓ あなたの会社の機密情報が中国政府に渡る可能性
```

#### 3. セキュリティ認証がない

SOC 2、ISO 27001などの国際的なセキュリティ認証を取得していないため、セキュリティ体制が不透明です。

#### 4. 法的リスク

万が一情報漏洩が発生した場合、中国企業を相手に法的措置を取ることは極めて困難です。

### ⚠️ 絶対に避けるべき用途

中華プロバイダーに以下の情報を送信してはいけません：

- 企業の機密情報
- 顧客データ
- ソースコード
- 設計書・要件定義書
- APIキーや認証情報

**結論：企業利用は推奨しません。個人利用でも機密情報は絶対に送信しないでください。**

---

## 開発現場別の推奨構成

### スタートアップ・小規模チーム

```
推奨：Anthropic Claude（claude.ai）

理由：
- デフォルトで学習に使用されない
- 低コスト
- すぐに使える
- セキュリティが高い

注意：機密情報は入力しない、またはサンドボックス環境でマスキング
```

### 中規模企業

```
推奨：AWS Bedrock（Claude）またはAzure OpenAI

理由：
- VPC内でセキュア
- スケーラブル
- 既存のクラウドインフラと統合しやすい
- コンプライアンス要件を満たせる

コスト：月額¥10,000〜¥100,000
```

### 大企業・金融機関

```
推奨：オンプレミス（Llama 3、Mistral）+ プライベートクラウド併用

理由：
- 最高レベルのセキュリティ
- データが完全に社内
- カスタマイズ可能
- コンプライアンス完全対応

コスト：初期¥10,000,000〜、運用¥500,000/月〜
```

---

## LLM選定チェックリスト

### セキュリティ要件
- [ ] 機密情報を扱うか？
- [ ] コンプライアンス要件はあるか？
- [ ] データの所在地制約はあるか？
- [ ] 学習データに使われても良いか？

### 予算
- [ ] 初期投資はいくらまで可能か？
- [ ] 月額運用コストはいくらまで可能か？

### 技術要件
- [ ] オンプレミス運用の技術力はあるか？
- [ ] GPUインフラは確保できるか？
- [ ] クラウド利用は許可されているか？

### 判定
- **全て「いいえ」** → Claude（claude.ai）
- **機密情報あり＋クラウドOK** → AWS Bedrock / Azure OpenAI
- **機密情報あり＋クラウドNG** → オンプレミス

---

## まとめ

| 現場 | 推奨 | 理由 |
|-----|------|------|
| スタートアップ | Claude（claude.ai） | セキュアで低コスト |
| 中規模企業 | AWS Bedrock / Azure OpenAI | VPC内でセキュア |
| 大企業・金融 | オンプレミス（Llama 3等） | 最高セキュリティ |

**絶対に避けるべき**：
- ❌ DeepSeek等の中華プロバイダー
- ❌ セキュリティポリシーが不明なプロバイダー
- ❌ 学習に使用されるサービス（機密情報を扱う場合）

**適切なLLM選択＋サンドボックス環境の活用で、セキュリティリスクを最小化できます。**
