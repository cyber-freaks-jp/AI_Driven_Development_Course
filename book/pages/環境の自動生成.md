# 環境の自動生成

## はじめに

開発環境のセットアップは時間がかかる作業ですが、AIを活用すれば自動化できます。この章では、Docker環境をAIで自動生成する方法を学びます。

## なぜDocker環境を自動生成するのか

### 従来の課題

**手動でのDocker環境構築：**
- Dockerfileの書き方を学ぶ必要がある
- docker-compose.ymlの設定が複雑
- ベストプラクティスを知らない
- トラブルシューティングに時間がかかる

**AIによる自動生成：**
- 自然言語で要件を伝えるだけ
- ベストプラクティスに沿った設定
- すぐに動く環境が手に入る
- カスタマイズも容易

## 基本的な使い方

### シンプルな例：Node.js環境

#### プロンプト

```
Node.jsの開発環境をDockerで構築したいです。

要件：
- Node.js 20
- Express.js アプリケーション
- ホットリロード対応
- ローカルの src ディレクトリをマウント
- ポート3000で公開

Dockerfile と docker-compose.yml を作成してください。
```

#### AIの出力

**Dockerfile:**
```dockerfile
FROM node:20-alpine

WORKDIR /app

# package.jsonとpackage-lock.jsonをコピー
COPY package*.json ./

# 依存関係をインストール
RUN npm install

# アプリケーションのソースをコピー
COPY . .

# ポートを公開
EXPOSE 3000

# 開発サーバーを起動（ホットリロード有効）
CMD ["npm", "run", "dev"]
```

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - ./src:/app/src
      - /app/node_modules
    environment:
      - NODE_ENV=development
    command: npm run dev
```

**package.json（devスクリプト）:**
```json
{
  "scripts": {
    "dev": "nodemon src/index.js"
  },
  "devDependencies": {
    "nodemon": "^3.0.0"
  }
}
```

### 実行方法

```bash
# イメージをビルド
docker-compose build

# コンテナを起動
docker-compose up

# バックグラウンドで起動
docker-compose up -d

# ログを確認
docker-compose logs -f

# 停止
docker-compose down
```

## 実践例1：フルスタックWeb アプリケーション

### プロンプト

```
フルスタックWebアプリケーションのDocker環境を構築してください。

構成：
- フロントエンド：React (Vite)
- バックエンド：Node.js + Express
- データベース：PostgreSQL
- キャッシュ：Redis

要件：
- 各サービスが独立したコンテナ
- データベースのデータは永続化
- 環境変数で設定を管理
- 開発環境用の設定
- ネットワークで各サービスを接続

docker-compose.yml、各Dockerfile、.envファイルを作成してください。
```

### AIの出力

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "5173:5173"
    volumes:
      - ./frontend/src:/app/src
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:3000
    depends_on:
      - backend
    networks:
      - app-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./backend/src:/app/src
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://user:password@postgres:5432/myapp
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - app-network

  postgres:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=myapp
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:

networks:
  app-network:
    driver: bridge
```

**frontend/Dockerfile:**
```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 5173

CMD ["npm", "run", "dev", "--", "--host", "0.0.0.0"]
```

**backend/Dockerfile:**
```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

EXPOSE 3000

CMD ["npm", "run", "dev"]
```

**.env:**
```
# データベース
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=myapp

# バックエンド
NODE_ENV=development
PORT=3000

# フロントエンド
VITE_API_URL=http://localhost:3000
```

### 使い方

```bash
# 全サービスを起動
docker-compose up

# 特定のサービスだけ起動
docker-compose up frontend backend

# ログを確認
docker-compose logs -f backend

# データベースに接続
docker-compose exec postgres psql -U user -d myapp

# Redisに接続
docker-compose exec redis redis-cli

# 全てのコンテナとボリュームを削除
docker-compose down -v
```

## 実践例2：マイクロサービスアーキテクチャ

### プロンプト

```
マイクロサービスアーキテクチャのDocker環境を構築してください。

サービス構成：
- API Gateway (Nginx)
- Auth Service (Node.js)
- User Service (Node.js)
- Product Service (Node.js)
- MongoDB (Auth, User用)
- PostgreSQL (Product用)
- RabbitMQ (メッセージキュー)

要件：
- 各マイクロサービスは独立
- API Gatewayでルーティング
- サービス間通信はRabbitMQ
- データベースは各サービスで分離
- ヘルスチェック機能
- ロギング統一

必要なファイルを全て生成してください。
```

### AIの出力例

**docker-compose.yml（一部抜粋）:**
```yaml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - auth-service
      - user-service
      - product-service
    networks:
      - microservices

  auth-service:
    build:
      context: ./services/auth
    environment:
      - MONGODB_URL=mongodb://mongodb:27017/auth
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - mongodb
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - microservices

  user-service:
    build:
      context: ./services/user
    environment:
      - MONGODB_URL=mongodb://mongodb:27017/user
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - mongodb
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - microservices

  product-service:
    build:
      context: ./services/product
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/product
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - postgres
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - microservices

  mongodb:
    image: mongo:7
    volumes:
      - mongo_data:/data/db
    networks:
      - microservices

  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=product
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - microservices

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - microservices

volumes:
  mongo_data:
  postgres_data:
  rabbitmq_data:

networks:
  microservices:
    driver: bridge
```

**nginx/nginx.conf:**
```nginx
events {
    worker_connections 1024;
}

http {
    upstream auth {
        server auth-service:3001;
    }
    
    upstream user {
        server user-service:3002;
    }
    
    upstream product {
        server product-service:3003;
    }

    server {
        listen 80;

        location /api/auth/ {
            proxy_pass http://auth/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        location /api/users/ {
            proxy_pass http://user/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        location /api/products/ {
            proxy_pass http://product/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

## 実践例3：Python機械学習環境

### プロンプト

```
Python機械学習のDocker環境を構築してください。

要件：
- Python 3.11
- Jupyter Notebook
- 必要なライブラリ（numpy, pandas, scikit-learn, tensorflow, pytorch）
- GPU対応（CUDA）
- データフォルダのマウント
- ノートブックの永続化

Dockerfile と docker-compose.yml を作成してください。
```

### AIの出力

**Dockerfile:**
```dockerfile
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# Pythonとpipのインストール
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace

# 必要なライブラリをインストール
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# Jupyter設定
RUN jupyter notebook --generate-config && \
    echo "c.NotebookApp.token = ''" >> ~/.jupyter/jupyter_notebook_config.py && \
    echo "c.NotebookApp.password = ''" >> ~/.jupyter/jupyter_notebook_config.py

EXPOSE 8888

CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root"]
```

**requirements.txt:**
```
jupyter==1.0.0
numpy==1.26.0
pandas==2.1.0
scikit-learn==1.3.0
matplotlib==3.8.0
seaborn==0.13.0
tensorflow==2.15.0
torch==2.1.0
torchvision==0.16.0
```

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  jupyter:
    build: .
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/workspace/notebooks
      - ./data:/workspace/data
      - ./models:/workspace/models
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

## よくあるカスタマイズ

### 1. マルチステージビルド

**プロンプト：**
```
本番環境用に最適化されたDockerfileを作成してください。
マルチステージビルドを使用して、イメージサイズを最小化してください。
```

### 2. 開発と本番の環境分離

**プロンプト：**
```
開発環境と本番環境で異なるdocker-compose設定を作成してください。
docker-compose.yml（共通）、docker-compose.dev.yml、docker-compose.prod.yml
の3ファイル構成にしてください。
```

### 3. CI/CD統合

**プロンプト：**
```
GitHub ActionsでDockerイメージをビルドしてプッシュする
ワークフローを作成してください。
```

## トラブルシューティング

### エラーが出た時のプロンプト例

```
以下のエラーが出ました：
[エラーメッセージ]

docker-compose.ymlを修正してください。
```

```
コンテナ間の通信ができません。
ネットワーク設定を確認して修正してください。
```

```
データベースの初期化が失敗します。
init.sqlファイルとdocker-compose.ymlを修正してください。
```

## ベストプラクティス

AIに依頼する際のポイント：

### 1. 明確な要件定義

```
❌ 悪い例：
「Node.jsの環境を作って」

✅ 良い例：
「Node.js 20のExpress開発環境を作成。
 要件：ホットリロード、PostgreSQL接続、Redis使用、
 開発環境と本番環境の切り替え可能」
```

### 2. セキュリティ考慮

```
「セキュリティベストプラクティスを考慮してください。
 - 本番環境でルート権限を使わない
 - 環境変数でシークレット管理
 - 最小権限の原則
 - 脆弱性のないベースイメージ使用」
```

### 3. パフォーマンス最適化

```
「以下を考慮してください：
 - レイヤーキャッシュの最適化
 - .dockerignore の作成
 - マルチステージビルド
 - イメージサイズの最小化」
```

## まとめ

**学んだこと：**

✓ Docker環境をAIで自動生成できる
✓ 複雑な構成も自然言語で指定可能
✓ ベストプラクティスに沿った設定が得られる
✓ カスタマイズや修正も簡単

**次のステップ：**

1. シンプルな環境から試す
2. 実際のプロジェクトに適用
3. カスタマイズを重ねる
4. チームで共有

Docker環境の構築時間を大幅に短縮し、開発に集中できるようになります！
