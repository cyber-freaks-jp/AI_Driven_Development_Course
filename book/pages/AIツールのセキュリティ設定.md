# AIツールのセキュリティ設定

AIツールの設定を適切に行うことで、情報漏洩や破壊的な操作などのセキュリティリスクを大幅に削減できます。

---

## AIのセキュリティリスクを防ぐ3つの設定

### 設定1：学習データとして使用されない設定

AIに渡した情報が、AIの学習データとして使われないようにする設定です。

**なぜ重要か（情報漏洩リスクの防止）**：
- AIに渡した情報が学習データとして使われると、インターネット上で情報公開されてしまう可能性があります
- 機密情報やAPIキーが漏洩するリスクがあります

**Cursorでの設定例**：

Cursorには、送信したコードを学習データとして使用させない設定があります。

具体的には、Cursorの設定画面で以下のような項目を**無効化**します：
- 「学習データとして使用する」のチェックを外す
- 「使用統計を送信する」のチェックを外す
- 「診断データを共有する」のチェックを外す

（具体的な設定手順は、Cursorのバージョンによって異なるため、公式ドキュメントを参照してください）

**他のツールでも同様の設定がありますので、ツールに応じて設定をググりましょう**

---

**⚠️ 重要：設定だけでは完全ではない**

いくら設定しても、**どこまで信用できるかはわかりません**：
- AIプロバイダーが意図せず情報漏洩するリスクもあります
- セキュリティ侵害や内部犯行の可能性もゼロではありません
- 設定が正しく機能しているか100%保証はできません

**結論：そもそも機密情報をAIに渡さないことが一番大事です。**

設定はリスク軽減のために行うべきですが、過信は禁物です。最も確実な対策は、**機密情報を最初から送信しないこと**です。

---

### 設定2：機密ファイルの除外設定

`.env`ファイルやAPIキーなど、機密情報を含むファイルをAIが読み取らないようにする設定です。

**なぜ重要か（情報漏洩リスクの防止）**：
- `.env`ファイルやAPIキーを含むファイルをAIに読み取らせると、そのまま送信されるリスクがあります
- パスワード、秘密鍵などの機密情報が含まれるファイルは絶対に送信してはいけません

**どうやって除外するのか**：

各AIツールには、**AIが読み取る対象から除外したいファイルを指定する仕組み**があります。

**Cursorの例：`.cursorignore`ファイル**

`.cursorignore`とは、Gitの`.gitignore`ファイルと似た役割を果たす設定ファイルです。このファイルに記述されたルールに従って、CursorのAIが読み込まないようにするファイルを定義できます。

プロジェクトのルートディレクトリに`.cursorignore`ファイルを作成し、除外したいファイルを記述します：

```
# .cursorignore の例
.env
.env.*
*.key
*.pem
id_rsa
*.p12
credentials.json
config/secrets.yml
config/database.yml
```

この設定により、Cursorは上記のファイルをAIに送信しません。

**他のツールでも同様の仕組みがあります**：
- GitHub Copilot：`.gitattributes`で除外
- Claude Code：`.claudeignore`で除外
- その他のツール：各ツールのドキュメントを参照

**除外すべきファイルの例**：
- 環境変数ファイル（`.env`、`.env.local`など）
- 秘密鍵（`.pem`、`.key`、`id_rsa`など）
- 認証情報（`credentials.json`、`secrets.yml`など）
- データベース設定（`database.yml`など）
- 証明書ファイル（`.p12`など）

### 設定3：操作権限の設定

AIが実行できる操作（ファイル削除、外部API呼び出しなど）を必要最小限に制限する設定です。

**なぜ重要か（破壊的な操作リスクの防止）**：
- AIが無制限にファイル削除、データベース操作、外部API実行などを行えると、破壊的な操作が実行されるリスクがあります
- 必要最小限の権限のみを与えることで、リスクを最小化できます

**Cursorでの設定例：`.cursorrules`ファイル**

`.cursorrules`とは、Cursorに対してAIの動作ルールを指示するための設定ファイルです。

プロジェクトのルートディレクトリに`.cursorrules`ファイルを作成し、AIに禁止したい操作を記述します：

```
# .cursorrules の例

## 禁止事項
- ファイルの削除は禁止
- データベースへの直接アクセス禁止
- 外部APIへの直接通信禁止
- 環境変数の読み取り禁止
- システムディレクトリ（/etc、/sys）への書き込み禁止

## 許可事項
- 新規ファイルの作成
- 既存ファイルの編集
- ローカルでのテスト実行
```

この設定により、CursorのAIは上記のルールに従って動作します。

**他のツールでも同様の仕組みがあります**：
- Claude Code：`.claude/instructions.md`でルール設定
- ChatGPT：Custom Instructionsでルール設定
- その他のツール：各ツールのドキュメントを参照

**禁止すべき操作の例**：
- ファイルの削除（`rm -rf`など）
- データベースへの直接アクセス
- 外部APIへの直接通信
- システムディレクトリへの書き込み
- `sudo`コマンドの使用

---

## セキュリティチェックリスト

使用しているAIツールで、以下の3つの設定が守られているか確認しましょう：

- [ ] **設定1：学習データとして使用されない設定**を有効化している
- [ ] **設定2：機密ファイルの除外設定**（`.cursorignore`、`.gitattributes`等）を行っている
- [ ] **設定3：操作権限の制限**（`.cursorrules`、`.claude/instructions.md`等）を設定している

---

## まとめ

### AIのセキュリティリスクを防ぐ3つの設定

1. **学習データとして使用されない設定を有効化**（情報漏洩リスクの防止）
   - Enterprise版・ビジネス版を使用
   - 個人版は必ず「学習に使用しない」設定

2. **機密ファイルを除外設定で保護**（情報漏洩リスクの防止）
   - `.env`、秘密鍵、認証情報などを除外
   - `.cursorignore`、`.gitattributes`を活用

3. **操作権限は必要最小限に制限**（破壊的な操作リスクの防止）
   - AIが実行できる操作を明示的に制限
   - `.cursorrules`、`.claude/instructions.md`でルール設定

**企業利用では、必ずEnterprise版またはビジネス版を使用してください。**
