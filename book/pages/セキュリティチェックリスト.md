# セキュリティチェックリスト

AI駆動開発を安全に実践するために、これまで学んだセキュリティ対策を実際に適用できているか確認しましょう。

**このチェックリストは、以下のセクションで学んだ内容をまとめたものです：**
- AIがもたらす3つのセキュリティリスク
- サンドボックス環境の重要性
- LLMの選定方法
- AIツールのセキュリティ設定

---

## 1. リスク理解のチェックリスト

### AI駆動開発の3つのリスクを理解していますか？

- [ ] **リスク1：情報漏洩**を理解している
  - AIに送信した情報がLLMプロバイダーのサーバーに送信されることを理解している
  - 学習データとして使われ、最悪の場合インターネット上に公開される可能性を理解している
  - 他のユーザーがAIに質問したときに、自分の機密情報が出力される可能性を理解している

- [ ] **リスク2：データや環境の破壊**を理解している
  - AIが破壊的なコード（`rm -rf /`、`DROP DATABASE`等）を生成する可能性を理解している
  - データベースの削除・変更、ファイルシステムの破壊、外部APIの実行リスクを理解している

- [ ] **リスク3：意図せぬコード生成**を理解している
  - SQLインジェクションなど、脆弱性を含むコードをAIが生成するリスクを理解している
  - 要件や仕様にマッチしないコードが生成されることを理解している

---

## 2. サンドボックス環境のチェックリスト

### サンドボックス環境を構築していますか？

- [ ] **サンドボックス環境でAIを動かしている**
  - Docker、仮想マシン、クラウド開発環境などを使用している
  - 本番DB、本番サーバーへの通信が遮断されている
  - いつでも作り直せる使い捨て環境である

- [ ] **機密情報のマスキングを徹底している**
  - サンドボックス環境に持ち込むデータは、必ず機密情報をマスキングしている
  - メールアドレスを`test@example.com`に置換している
  - APIキーをダミー値に置換している
  - 決済情報テーブルなど、機密性の高いデータを除外している

- [ ] **完全自律実行モードを安全に使える環境を構築している**（オプション）
  - サンドボックス環境であることを前提に、完全自律実行モードを使用している
  - AIが暴走してもノーリスクな環境である

---

## 3. LLM選定のチェックリスト

### プロジェクトに適したLLMを選定していますか？

#### 個人開発・スタートアップの場合

- [ ] **クラウドLLMを使用している**
  - OpenAI（ChatGPT）、Anthropic（Claude）、Google（Gemini）などを使用
  - 低コスト・運用負荷ゼロのメリットを活かしている
  - 機密情報を扱わないプロジェクトである

#### 中規模企業の場合

- [ ] **プライベートクラウド（VPC）を検討している**
  - AWS Bedrock、Azure OpenAI Service、Google Cloud Vertex AIなどを検討
  - データが自社のVPC内に留まる環境を構築している
  - セキュリティコントロールが可能な環境である

#### 金融機関・政府機関の場合

- [ ] **オンプレミスLLMを検討している**
  - Llama 3、Mistral、QwenなどのオープンソースLLMを使用
  - データが完全に社内に留まる環境を構築している
  - 高性能GPUと運用体制を整備している

#### 全てのプロジェクトで確認すべきこと

- [ ] **中華プロバイダーを避けている**
  - DeepSeekなど中国製のLLMプロバイダーを使用していない
  - プライバシーポリシーが不明瞭なプロバイダーを避けている
  - 国家の政治的なリスクを考慮している

---

## 4. AIツールのセキュリティ設定チェックリスト

### 設定1：学習データとして使用されない設定

- [ ] **学習データとして使用されない設定を有効化している**
  - Cursorの場合：「学習データとして使用する」のチェックを外している
  - Cursorの場合：「使用統計を送信する」のチェックを外している
  - Cursorの場合：「診断データを共有する」のチェックを外している
  - 他のツールでも同様の設定を確認している

- [ ] **設定だけでは完全ではないことを理解している**
  - AIプロバイダーが意図せず情報漏洩するリスクもあることを理解している
  - セキュリティ侵害や内部犯行の可能性もゼロではないことを理解している
  - **そもそも機密情報をAIに渡さないことが一番大事**であることを理解している

### 設定2：機密ファイルの除外設定

- [ ] **機密ファイルの除外設定を行っている**
  - Cursorの場合：`.cursorignore`ファイルを作成している
  - Claude Codeの場合：`.claudeignore`ファイルを作成している
  - GitHub Copilotの場合：`.gitattributes`で除外している

- [ ] **除外すべきファイルを全て設定している**
  - 環境変数ファイル（`.env`、`.env.*`）
  - 秘密鍵（`.pem`、`.key`、`id_rsa`）
  - 認証情報（`credentials.json`、`secrets.yml`）
  - データベース設定（`database.yml`）
  - 証明書ファイル（`.p12`）

**Cursorの`.cursorignore`例：**
```
.env
.env.*
*.key
*.pem
id_rsa
*.p12
credentials.json
config/secrets.yml
config/database.yml
```

### 設定3：操作権限の設定

- [ ] **操作権限の制限を設定している**
  - Cursorの場合：`.cursorrules`ファイルを作成している
  - Claude Codeの場合：`.claude/instructions.md`でルール設定している
  - ChatGPTの場合：Custom Instructionsでルール設定している

- [ ] **禁止すべき操作を全て設定している**
  - ファイルの削除（`rm -rf`など）
  - データベースへの直接アクセス
  - 外部APIへの直接通信
  - 環境変数の読み取り
  - システムディレクトリへの書き込み
  - `sudo`コマンドの使用

**Cursorの`.cursorrules`例：**
```
## 禁止事項
- ファイルの削除は禁止
- データベースへの直接アクセス禁止
- 外部APIへの直接通信禁止
- 環境変数の読み取り禁止
- システムディレクトリ（/etc、/sys）への書き込み禁止

## 許可事項
- 新規ファイルの作成
- 既存ファイルの編集
- ローカルでのテスト実行
```

---

## 5. コードレビューとテストのチェックリスト

### AIが生成したコードを人間がレビューしていますか？

- [ ] **AIが生成したコードを必ずレビューしている**
  - セキュリティリスク（SQLインジェクション等）がないか確認している
  - 機密情報がハードコードされていないか確認している
  - 要件や仕様にマッチしているか確認している

- [ ] **外部APIとの通信を確認している**
  - AIが意図しない外部APIにアクセスしていないか確認している
  - APIキーやトークンが適切に管理されているか確認している

- [ ] **テストを実施している**
  - AIが生成したコードに対してテストを実施している
  - セキュリティテストを実施している

---

## 6. 機密情報管理のチェックリスト

### 機密情報をAIに送信していませんか？

- [ ] **機密情報をAIに送信していない**
  - パスワード、秘密鍵、APIキーなどを直接AIに送信していない
  - 機密情報が含まれるファイルを除外設定で保護している

- [ ] **本番データを開発環境で使用していない**
  - テストデータやダミーデータを使用している
  - 個人情報や機密情報を含むデータを使用していない

- [ ] **環境変数の管理を適切に行っている**
  - 本番環境の環境変数を開発環境で使用していない
  - `.env`ファイルを`.gitignore`に追加している

---

## 7. 企業利用のチェックリスト

### 企業でAI駆動開発を導入していますか？

- [ ] **Enterprise版またはビジネス版を使用している**
  - 個人版ではなく、Enterprise版またはビジネス版を使用している
  - データが学習に使用されない契約であることを確認している

- [ ] **利用規約とプライバシーポリシーを確認している**
  - データの保存期間、利用目的、第三者提供について確認している
  - 企業のセキュリティポリシーに適合していることを確認している

---

## まとめ：必ず守るべき3つのルール

このチェックリストを定期的に確認し、AI駆動開発のセキュリティを維持しましょう。

**特に以下の3点は必ず守ってください：**

### 1. サンドボックス環境でAIを動かす
- 本番環境から隔離された環境でAIを実行する
- 機密情報をマスキングする
- いつでも作り直せる使い捨て環境にする

### 2. 機密情報をAIに送信しない
- 学習データとして使用されない設定を有効化する（ただし過信しない）
- 機密ファイルの除外設定を徹底する
- そもそも機密情報をAIに渡さない

### 3. 人間がコードレビューとテストをする
- AIが生成したコードを必ずレビューする
- セキュリティリスクがないか確認する
- テストを実施する

---

**安全なAI駆動開発を実践することで、生産性向上とセキュリティの両立が可能になります。**
