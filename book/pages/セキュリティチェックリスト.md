# セキュリティチェックリスト

AI駆動開発を安全に実践するために、これまで学んだセキュリティ対策を実際に適用できているか確認しましょう。

---

## 1. リスク理解のチェックリスト

### リスク1：情報漏洩

- [ ] ChatGPTなどのクラウドLLMを利用する際、AIに渡した情報がOpenAIなどの外部サーバーに送信されることを理解している
- [ ] AIに渡したデータは学習データとして使われ、最悪の場合インターネット上に公開される可能性を理解している

### リスク2：データや環境の破壊

- [ ] AIが破壊的なコード（`rm -rf /`、`DROP DATABASE`等）を実行する可能性を理解している
- [ ] データベースの削除・変更、ファイルシステムの破壊、外部API実行などが行われる可能性があることを理解している

### リスク3：意図せぬコード生成

- [ ] SQLインジェクションなど、脆弱性を含むコードをAIが生成するリスクを理解している
- [ ] 要件や仕様にマッチしないコードが生成されることを理解している

---

## 2. サンドボックス環境のチェックリスト

### どんな環境でAIを動かしているか？

- [ ] Dockerなど隔離されたサンドボックス環境でのみAIを使用している
- [ ] その環境は、本番DB・本番サーバーへの通信が完全に遮断されている(SSHも出来ない。本番APIも実行できない)
- [ ] その環境は、いつでも作り直せる使い捨て環境である
- [ ] ローカルPCのOS上に直にAIをインストールするのは危険なことを知っており、Dockerなどのサンドボックス上でAIを動かしている
### 機密情報のマスキングを徹底している

サンドボックス環境に持ち込むデータは、必ず機密情報を除外またはマスキング(データの塗りつぶし)をしているか？

- [ ] データベース
- [ ] ログファイル
- [ ] .envなどの環境変数

---

## 3. LLM選定のチェックリスト

- [ ] LLMの提供方法には「クラウド型」「VPC型」「オンプレミス型」などの種類があることを理解している
- [ ] どのLLMを使うべきかのポリシーが明確に定まっている
- [ ] DeepSeekなど中国製のLLMプロバイダーを使用していない

---

## 4. AIツールのセキュリティ設定チェックリスト

### 設定1：学習データとして使用されない設定を有効化している

- [ ] Cursorの場合：「学習データとして使用する」のチェックを外している
- [ ] Cursorの場合：「使用統計を送信する」のチェックを外している
- [ ] Cursorの場合：「診断データを共有する」のチェックを外している
- [ ] 他のツールでも同様の設定を確認している

### 設定だけでは完全ではないことを理解している

- [ ] AIプロバイダーが意図せず情報漏洩するリスクもあることを理解している
- [ ] セキュリティ侵害や内部犯行の可能性もゼロではないことを理解している
- [ ] **そもそも機密情報をAIに渡さないことが一番大事**であることを理解している

### 設定2：機密ファイルの除外設定を行っている

- [ ] Cursorの場合：`.cursorignore`ファイルを作成している
- [ ] Claude Codeの場合：`.claudeignore`ファイルを作成している
- [ ] GitHub Copilotの場合：`.gitattributes`で除外している

### 除外すべきファイルを全て設定している

- [ ] 環境変数ファイル（`.env`、`.env.*`）
- [ ] 秘密鍵（`.pem`、`.key`、`id_rsa`）
- [ ] 認証情報（`credentials.json`、`secrets.yml`）
- [ ] データベース設定（`database.yml`）
- [ ] 証明書ファイル（`.p12`）

**Cursorの`.cursorignore`例：**
```
.env
.env.*
*.key
*.pem
id_rsa
*.p12
credentials.json
config/secrets.yml
config/database.yml
```

### 設定3：操作権限の制限を設定している

- [ ] Cursorの場合：`.cursorrules`ファイルを作成している
- [ ] Claude Codeの場合：`.claude/instructions.md`でルール設定している
- [ ] ChatGPTの場合：Custom Instructionsでルール設定している

### 禁止すべき操作を全て設定している

- [ ] ファイルの削除（`rm -rf`など）
- [ ] データベースへの直接アクセス
- [ ] 外部APIへの直接通信
- [ ] 環境変数の読み取り
- [ ] システムディレクトリへの書き込み
- [ ] `sudo`コマンドの使用

**Cursorの`.cursorrules`例：**
```
## 禁止事項
- ファイルの削除は禁止
- データベースへの直接アクセス禁止
- 外部APIへの直接通信禁止
- 環境変数の読み取り禁止
- システムディレクトリ（/etc、/sys）への書き込み禁止

## 許可事項
- 新規ファイルの作成
- 既存ファイルの編集
- ローカルでのテスト実行
```

---

## 5. コードレビューとテストのチェックリスト

### AIが生成したコードを必ずレビューしている

- [ ] セキュリティリスク（SQLインジェクション等）がないか確認している
- [ ] 機密情報がハードコードされていないか確認している
- [ ] 要件や仕様にマッチしているか確認している

### 外部APIとの通信を確認している

- [ ] AIが意図しない外部APIにアクセスしていないか確認している
- [ ] APIキーやトークンが適切に管理されているか確認している

### テストを実施している

- [ ] AIが生成したコードに対してテストを実施している
- [ ] セキュリティテストを実施している

---

## 6. 機密情報管理のチェックリスト

### 機密情報をAIに送信していない

- [ ] パスワード、秘密鍵、APIキーなどを直接AIに送信していない
- [ ] 機密情報が含まれるファイルを除外設定で保護している

### 本番データを開発環境で使用していない

- [ ] テストデータやダミーデータを使用している
- [ ] 個人情報や機密情報を含むデータを使用していない

### 環境変数の管理を適切に行っている

- [ ] 本番環境の環境変数を開発環境で使用していない
- [ ] `.env`ファイルを`.gitignore`に追加している

---

## 7. 企業利用のチェックリスト

### Enterprise版またはビジネス版を使用している

- [ ] 個人版ではなく、Enterprise版またはビジネス版を使用している
- [ ] データが学習に使用されない契約であることを確認している

### 利用規約とプライバシーポリシーを確認している

- [ ] データの保存期間、利用目的、第三者提供について確認している
- [ ] 企業のセキュリティポリシーに適合していることを確認している

---

## まとめ：必ず守るべき3つのルール

このチェックリストを定期的に確認し、AI駆動開発のセキュリティを維持しましょう。

**特に以下の3点は必ず守ってください：**

### 1. サンドボックス環境でAIを動かす
- [ ] 本番環境から隔離された環境でAIを実行する
- [ ] 機密情報をマスキングする
- [ ] いつでも作り直せる使い捨て環境にする

### 2. 機密情報をAIに送信しない
- [ ] 学習データとして使用されない設定を有効化する（ただし過信しない）
- [ ] 機密ファイルの除外設定を徹底する
- [ ] そもそも機密情報をAIに渡さない

### 3. 人間がコードレビューとテストをする
- [ ] AIが生成したコードを必ずレビューする
- [ ] セキュリティリスクがないか確認する
- [ ] テストを実施する

---

**安全なAI駆動開発を実践することで、生産性向上とセキュリティの両立が可能になります。**
