# トークンとは

## はじめに

トークンは、LLM（大規模言語モデル）が文章を理解し、処理するための基本単位です。この章では、トークンの概念と重要性について説明します。

## トークンとは

トークンは、テキストを小さな単位に分割したもので、LLMが処理できる形式です。

### 基本概念

1. トークン化（Tokenization）

   - テキストの分割処理
   - 単語や文字の組み合わせ
   - モデル固有の方式

2. トークンの種類

   - 単語トークン
   - サブワードトークン
   - 文字トークン

3. 処理方法
   - エンコーディング
   - デコーディング
   - トークンID への変換

## トークン数の目安

### 日本語の場合

- 1トークン ≈ 0.5〜1文字
- 100文字 ≈ 100〜200トークン
- 1,000文字 ≈ 1,000〜2,000トークン

### 英語の場合

- 1トークン ≈ 4文字（平均）
- 100単語 ≈ 75トークン
- 1,000単語 ≈ 750トークン

### 具体例

```
例文: "こんにちは、世界！"
トークン数: 約8〜10トークン

例文: "Hello, World!"
トークン数: 約4トークン
```

## トークンの重要性

### 1. コストへの影響

- 料金計算の基準
- 入力と出力の合計
- API使用量の測定

### 2. コンテキストウィンドウ

- 処理可能な上限
- 会話履歴の管理
- 長文の取り扱い

### 3. パフォーマンス

- 処理速度
- レスポンスタイム
- 効率的な利用

## トークン数の確認方法

### 1. 各サービスの提供ツール

- OpenAI Tokenizer
- Anthropic Console
- モデル固有のツール

### 2. プログラムでの計算

```python
# OpenAI の例
import tiktoken

encoding = tiktoken.encoding_for_model("gpt-4")
tokens = encoding.encode("こんにちは、世界！")
print(f"トークン数: {len(tokens)}")
```

### 3. おおよその見積もり

- 文字数からの概算
- 単語数からの概算
- 事前のテスト

## トークンの最適化

### 1. 無駄の削減

- 不要な空白の除去
- 冗長な表現の簡略化
- 簡潔な文章

### 2. 効率的な構造

- 箇条書きの活用
- 明確な指示
- 必要最小限の情報

### 3. コンテキストの管理

- 古い履歴の削除
- 要約の活用
- 段階的な情報提供

## まとめ

トークンは LLM の基本単位であり、コストやパフォーマンスに直接影響します。トークンを理解し、適切に管理することで、より効率的な AI 活用が可能になります。
